{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Conv2D,Conv2DTranspose,MaxPool2D,concatenate,Dropout,Lambda\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "PATH_DATASET = os.path.join(ROOT_DIR,'dataset')\n",
    "\n",
    "X_TRAIN_PATH=os.path.join(PATH_DATASET,'x_train.npy')\n",
    "Y_TRAIN_PATH=os.path.join(PATH_DATASET,'y_train.npy')\n",
    "X_TEST_PATH=os.path.join(PATH_DATASET,'x_test.npy')\n",
    "\n",
    "\n",
    "# Preparing Data\n",
    "X_train = np.load(X_TRAIN_PATH)\n",
    "Y_train = np.load(Y_TRAIN_PATH)\n",
    "X_test = np.load(X_TEST_PATH)\n",
    "\n",
    "# Build Model (U-Net)\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "img_channels = 3\n",
    "\n",
    "drop_rate=0.2\n",
    "##### Encoder ######\n",
    "inputs = Input((img_width,img_height,img_channels))\n",
    "scaled_inputs = Lambda(lambda x: x / 255)(inputs)\n",
    "# Block 1 input size : 128 128 3\n",
    "conv1 = Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block1_conv1\")(scaled_inputs)\n",
    "conv1 = Dropout(drop_rate)(conv1)\n",
    "conv1 = Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block1_conv2\")(conv1)\n",
    "pool1 = MaxPool2D((2,2),name=\"block1_poll1\")(conv1)\n",
    "# Block 2 input size : 64 64 16\n",
    "conv2 = Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block2_conv1\")(pool1)\n",
    "conv2 = Dropout(drop_rate)(conv2)\n",
    "conv2 = Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block2_conv2\")(conv2)\n",
    "pool2 = MaxPool2D((2,2),name=\"block2_poll1\")(conv2)\n",
    "# Block 3 input size : 32 32 32\n",
    "conv3 = Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block3_conv1\")(pool2)\n",
    "conv3 = Dropout(drop_rate)(conv3)\n",
    "conv3 = Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block3_conv2\")(conv3)\n",
    "pool3 = MaxPool2D((2,2),name=\"block3_poll1\")(conv3)\n",
    "# Block 4 input size : 16 16 64\n",
    "conv4 = Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block4_conv1\")(pool3)\n",
    "conv4 = Dropout(drop_rate)(conv4)\n",
    "conv4 = Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block4_conv2\")(conv4)\n",
    "pool4 = MaxPool2D((2,2),name=\"block4_poll1\")(conv4)\n",
    "# Block 5 input size : 8 8 128\n",
    "conv5 = Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block5_conv1\")(pool4)\n",
    "conv5 = Dropout(drop_rate)(conv5)\n",
    "conv5 = Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block5_conv2\")(conv5)\n",
    "\n",
    "##### Decoder ######\n",
    "# Block 6 input size : 8 8 256\n",
    "convt6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same',name=\"block6_upsample1\")(conv5) # 8 8 256 -> 16 16 128\n",
    "concat6 = concatenate([conv4,convt6]) # 16 16 128 + 16 16 128 = 16 16 256\n",
    "conv6 = Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block6_conv1\")(concat6)\n",
    "conv6 = Dropout(drop_rate)(conv6)\n",
    "conv6 = Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block6_conv2\")(conv6)\n",
    "# Block 7 input size : 16 16 128\n",
    "convt7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same',name=\"block7_upsample1\")(conv6) # 16 16 128 -> 32 32 64\n",
    "concat7 = concatenate([conv3,convt7]) # 32 32 64 + 32 32 64 = 32 32 128\n",
    "conv7 = Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block7_conv1\")(concat7)\n",
    "conv7 = Dropout(drop_rate)(conv7)\n",
    "conv7 = Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block7_conv2\")(conv7)\n",
    "# Block 8 input size : 32 32 64\n",
    "convt8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same',name=\"block8_upsample1\")(conv7) # 32 32 64 -> 64 64 32\n",
    "concat8 = concatenate([conv2,convt8]) # 64 64 32 + 64 64 32 = 64 64 64\n",
    "conv8 = Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block8_conv1\")(concat8)\n",
    "conv8 = Dropout(drop_rate)(conv8)\n",
    "conv8 = Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block8_conv2\")(conv8)\n",
    "# Block 9 input size : 64 64 32\n",
    "convt9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same',name=\"block9_upsample1\")(conv8) # 64 64 32 -> 128 128 16\n",
    "concat9 = concatenate([conv1,convt9]) # 128 128 16 + 128 128 16 = 128 128 32\n",
    "conv9 = Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block9_conv1\")(concat9)\n",
    "conv9 = Dropout(drop_rate)(conv9)\n",
    "conv9 = Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',name=\"block9_conv2\")(conv9)\n",
    "\n",
    "outputs = Conv2D(1,(1,1),activation='sigmoid',name=\"output\")(conv9) # 128 128 1\n",
    "\n",
    "model = Model(inputs=inputs,outputs=outputs)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "model.summary()\n",
    "####################\n",
    "\n",
    "model_best_path = os.path.join(ROOT_DIR,'unet_nuclei_best.h5')\n",
    "# Set Callback, Checkpoint\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.ModelCheckpoint(model_best_path,monitor='val_loss',save_best_only=True),\n",
    "             tf.keras.callbacks.EarlyStopping(patience=3,monitor='val_loss'),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=os.path.join(ROOT_DIR,'logs'))\n",
    "]\n",
    "# Train model\n",
    "history = model.fit(X_train,Y_train,validation_split=0.1,batch_size=16,epochs=50,callbacks=callbacks)\n",
    "\n",
    "model.load_weights(model_best_path)\n",
    "# Evaludate model\n",
    "preds_train = model.predict(X_train)\n",
    "preds_train_mask = (preds_train>0.5).astype(np.uint8)\n",
    "preds_test = model.predict(X_test)\n",
    "preds_test_mask = (preds_test>0.5).astype(np.uint8)\n",
    "\n",
    "# Train Prediction and Ground Truth\n",
    "indices = np.random.randint(0,X_train.shape[0],10)\n",
    "for idx in indices:\n",
    "  plt.subplot(121)\n",
    "  plt.title(\"Train Image\")\n",
    "  imshow(X_train[idx])\n",
    "  plt.subplot(122)\n",
    "  plt.title(\"Ground Truth\")\n",
    "  imshow(np.squeeze(preds_train_mask[idx]),cmap=\"gray\")\n",
    "  plt.show()\n",
    "\n",
    "# Visualize Test Prediction\n",
    "indices = np.random.randint(0,X_test.shape[0],10)\n",
    "for idx in indices:\n",
    "  plt.subplot(121)\n",
    "  plt.title(\"Test Image\")\n",
    "  imshow(X_test[idx])\n",
    "  plt.subplot(122)\n",
    "  plt.title(\"Test Prediction\")\n",
    "  imshow(np.squeeze(preds_test_mask[idx]),cmap=\"gray\")\n",
    "  plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
